{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Google Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/giordamaug/IEEE-JBHI/blob/main/CV_emb_lgbm.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    matthews_corrcoef, confusion_matrix, accuracy_score, roc_auc_score,\n",
    "    precision_score, recall_score, f1_score\n",
    ")\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dowload source files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/giordamaug/IEEE-JBHI/main/spleen_synth_dataset.json\n",
    "!wget https://raw.githubusercontent.com/giordamaug/IEEE-JBHI/main/targets.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Settings:\n",
    "    pathologies = \"0,1,2,3,4,5,6,7\"\n",
    "    input_file = \"spleen_ina_dataset.json\"\n",
    "    target_file = \"targets.csv\"\n",
    "    splen = \"1\"\n",
    "    min_events = 3\n",
    "    display = False\n",
    "    to_latex = False\n",
    "    use_vars = \"static\"\n",
    "\n",
    "args = Settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 31871,
     "status": "aborted",
     "timestamp": 1747823126525,
     "user": {
      "displayName": "Maurizio Giordano",
      "userId": "11661605724852130605"
     },
     "user_tz": -120
    },
    "id": "vMWhX4V-rymy"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "767ab1f2c3e4459a8ec922502f6c9510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting events:   0%|          | 0/2399 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_static shape: (2399, 23)\n",
      "ATTRIBUTES: ['base_pathology_area', 'bmi', 'days_after', 'days_before', 'dosage_num', 'drug', 'dyslipidemia', 'eventi_infettivi', 'gender', 'genotype_alpha1', 'genotype_alpha2', 'genotype_beta1', 'genotype_beta2', 'hbf', 'heparin', 'id', 'is_splenectomized?', 'primary_pathology', 'smoking', 'splenectomy_indication', 'splenectomy_method', 'splenectomy_response', 'tsh']\n"
     ]
    }
   ],
   "source": [
    "sequences = {}\n",
    "with open(args.input_file) as f:\n",
    "    synt_list = json.load(f)\n",
    "    for elem in tqdm(synt_list, desc=\"Extracting events\"):\n",
    "        sequences[elem['id']] = [(elem['events'][i]['event'], elem['events'][i]['date']) for i in range(len(elem['events']))]\n",
    "    sequences\n",
    "    Xstatic = pd.read_json(args.input_file).drop(columns=['events'])\n",
    "\n",
    "    print(f\"X_static shape: {Xstatic.shape}\")\n",
    "    print(f\"ATTRIBUTES: {sorted(Xstatic.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Builder\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, sequences):\n",
    "        self.sequences = sequences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.sequences[idx]\n",
    "\n",
    "# LSTM embedding model\n",
    "class LSTMEmbeddingModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, pooling=False):\n",
    "        super().__init__()\n",
    "        self.pooling = pooling\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True, bidirectional=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        output, (hn, cn) = self.lstm(embedded)\n",
    "        if self.pooling:\n",
    "            return output.mean(dim=1)\n",
    "        else:\n",
    "            return hn.squeeze(0)\n",
    "\n",
    "    def train_model(self, dataloader, num_epochs=10, enable_plot=False, disable=False):\n",
    "\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        criterion = torch.nn.MSELoss()\n",
    "\n",
    "        loss_history = []\n",
    "\n",
    "        self.train()\n",
    "        pbar = tqdm(range(num_epochs), disable=disable, desc=f\"Embedding:\")\n",
    "        for epoch in pbar:\n",
    "            total_loss = 0\n",
    "            for batch in dataloader:\n",
    "                optimizer.zero_grad()\n",
    "                batch = batch.long()\n",
    "                output = self(batch)\n",
    "\n",
    "                target = torch.zeros_like(output)\n",
    "                loss = criterion(output, target)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            avg_loss = total_loss / len(dataloader)\n",
    "            pbar.set_description(f\"Embedding: Loss {avg_loss:.4f}\")\n",
    "            loss_history.append(avg_loss)\n",
    "\n",
    "            if enable_plot:\n",
    "                clear_output(wait=True)\n",
    "                plt.plot(loss_history, label=\"Loss\")\n",
    "                plt.xlabel(\"Epoch\")\n",
    "                plt.ylabel(\"Loss\")\n",
    "                plt.title(\"Training Loss Over Time\")\n",
    "                plt.legend()\n",
    "                plt.grid()\n",
    "                plt.show()\n",
    "\n",
    "def similarity_matrix(events, attributes, targets, emb1, emb2):\n",
    "    attributes = [a.lower() for a in attributes]\n",
    "    targets = [t.lower() for t in targets]\n",
    "    zero_data = np.ones((len(events), len(attributes)))\n",
    "    X_df = pd.DataFrame(zero_data, columns=attributes, index=events.keys())\n",
    "\n",
    "    Wmul = emb1.T@emb2\n",
    "    for id, dcount in tqdm(events.items(), desc=\"Risk calculating\"):\n",
    "        for concept in dcount.keys():\n",
    "            concept_l = concept.lower()\n",
    "            if concept_l in attributes:\n",
    "                X_df.loc[id, concept_l] += dcount[concept] * np.array([math.exp(Wmul[concept_l][disease]) for disease in targets]).mean()\n",
    "    return X_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection of patients by pathology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 31869,
     "status": "aborted",
     "timestamp": 1747823126525,
     "user": {
      "displayName": "Maurizio Giordano",
      "userId": "11661605724852130605"
     },
     "user_tz": -120
    },
    "id": "j4xqOpJuJnJv"
   },
   "outputs": [],
   "source": [
    "# === Event sequence generator =========\n",
    "def truncevents(sequences, infection_list, max_inf=1, max_flwup=5, debug=False):\n",
    "    trunc_sequences = {}\n",
    "    # truncate event sequence to the k-th occurrence of target\n",
    "    for id in tqdm(sequences.keys(), desc=f\"Truncating to {max_inf}\"):\n",
    "        inf_cnt = 0\n",
    "        flw_cnt = 0\n",
    "        new_evset = set()\n",
    "        for e, d in sequences[id]:\n",
    "              if e in infection_list:\n",
    "                if debug: print(f\"INF[{id}] {e}\")\n",
    "                new_evset.add((e,d))\n",
    "                inf_cnt += 1\n",
    "                if inf_cnt >= max_inf: break\n",
    "              elif e == \"followup\" :\n",
    "                new_evset.add((e,d))\n",
    "                flw_cnt += 1\n",
    "                if flw_cnt >= max_flwup: break\n",
    "              else:\n",
    "                if debug: print(f\"eve[{id}] {e}\")\n",
    "                new_evset.add((e,d))\n",
    "        trunc_sequences[id] = sorted(list(new_evset), key=lambda x: x[1])\n",
    "    return trunc_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "aborted",
     "timestamp": 1747823126554,
     "user": {
      "displayName": "Maurizio Giordano",
      "userId": "11661605724852130605"
     },
     "user_tz": -120
    },
    "id": "-0c46KfaKoSw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCABOLARY SIZE: 101\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08dd2f28ffdd48da839eed0e8556ebab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating to 1:   0%|          | 0/2399 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1ST TARGET SEQUENCE: [('intervention adenoidectomy', '2020-01-01'), ('bacterial infection of the respiratory tract', '2020-01-17')]\n",
      "# INFECTED: 1030\n",
      "TARGETS: ['bacterial/viral infection of the heart', 'bacterial/viral infection of the throat', 'parasitic infection of the blood', 'fungal infection of the skin', 'bacterial infection of the gallbladder', 'bacterial infection of the biliary tract', 'autoimmune or inflammatory infection of the blood vessels', 'intestinal parasitic infection', 'viral infection of the skin and mucous membranes', 'bacterial infection of the pleural cavities', 'bacterial/viral infection of the pancreas', 'systemic viral infection', 'other infection', 'bacterial/viral infection of the respiratory tract', 'bacterial/parasitic infection of the blood', 'viral/automimetic infection of the eye', 'zoonotic bacterial infection', 'viral infection of the respiratory tract', 'bacterial/viral infection of the oral mucous membranes', 'bacterial infection of the vertebrae', 'bacterial infection of the breast', 'bacterial infection of the urogenital system', 'bacterial infection of the soft tissues', 'bacterial/viral infection of the ear', 'bacterial infection of the bones', 'bacterial/viral infection of the joints', 'localised bacterial infection', 'bacterial/viral infection of the gastrointestinal system', 'bacterial streptococcal infection', 'systemic parasitic infection', 'bacterial infection of the gastrointestinal system', 'sexually transmitted viral infection', 'respiratory viral infection', 'bacterial infection of the skin', 'systemic infection', 'bacterial infection of the respiratory tract', 'viral infection of the liver', 'bacterial/viral infection of the central nervous system', 'viral infection', 'bacterial infection of the urinary tract', 'bacterial infection of the cardiovascular system']\n",
      "# [0,1,2,3,4,5,6,7] PATIENTS: 1188\n"
     ]
    }
   ],
   "source": [
    "# Patient selection by pathology\n",
    "def select_patients(df, event_counts, pathologies, splen_flags=[0,1], min_ev_count=3):\n",
    "    filtered_events = {}\n",
    "    selected_patient_ids = df[\n",
    "        df['base_pathology_area'].isin(pathologies) &\n",
    "        df['is_splenectomized?'].isin(splen_flags)\n",
    "    ].index.tolist()\n",
    "\n",
    "    filtered_events = {\n",
    "        int(key): value for key, value in event_counts.items()\n",
    "        if int(key) in selected_patient_ids and len(value.keys()) > min_ev_count\n",
    "    }\n",
    "\n",
    "    selected_patient_ids = np.array(list(filtered_events.keys()))\n",
    "    return selected_patient_ids, filtered_events\n",
    "\n",
    "# === Vocabulary building and target event counting ===\n",
    "event_counts = {}\n",
    "tot_counts = {}\n",
    "for k, v in sequences.items():\n",
    "    lista = list(map(lambda x: x[0], filter(lambda x: x[0] != ['followup'], v)))\n",
    "    flat_list = list(itertools.chain.from_iterable(lista)) if lista and isinstance(lista[0], list) else lista\n",
    "    event_counts[k] = dict((x, flat_list.count(x)) for x in set(flat_list))\n",
    "    tot_counts[int(k)] = len(flat_list)\n",
    "\n",
    "\n",
    "# === Vocabulary === \n",
    "vocab = set()\n",
    "for patient_events in sequences.values():\n",
    "    for event,_ in patient_events:\n",
    "        vocab.update([event] if isinstance(event, str) and event != 'followup' else event)\n",
    "word_to_idx = {word: idx for idx, word in enumerate(sorted(vocab))}\n",
    "#word_to_idx[\"followup\"] = 0\n",
    "idx_to_word = {i: word for word, i in word_to_idx.items()}\n",
    "print(f\"VOCABOLARY SIZE: {len(vocab)}\")\n",
    "\n",
    "# Index sequences and padding (for embeddings)\n",
    "indexed_sentences = [[word_to_idx[word] if word in word_to_idx else 0\n",
    "                      for _, word in patient_events if word in word_to_idx]\n",
    "                     for patient_events in sequences.values()]\n",
    "padded_sentences = pad_sequence([torch.tensor(s) for s in indexed_sentences], batch_first=True)\n",
    "\n",
    "# Target infection\n",
    "targets = pd.read_csv(args.target_file)['targets'].to_list()\n",
    "embed_attributes = [w for w in sorted(vocab) if w not in targets]\n",
    "\n",
    "# ===== Truncate sequences to first infection or up to fifth follow-up\n",
    "sequences = truncevents(sequences, targets)\n",
    "\n",
    "infected_ids = [id for id,l in sequences.items() if any([x[0].strip().lower() in targets for x in l]) ]\n",
    "infected_ids_last = [id for id,l in sequences.items() if len(l) > 0 and l[-1][0] in targets]\n",
    "print(f\"1ST TARGET SEQUENCE: {sequences[infected_ids[0]]}\")\n",
    "print(f\"# INFECTED: {len(infected_ids)}\")\n",
    "print(f\"TARGETS: {targets}\")\n",
    "\n",
    "# === Patient selection ===\n",
    "pathologies = []\n",
    "for p in args.pathologies.split(','):\n",
    "    if int(p.strip()) in Xstatic['base_pathology_area'].unique():\n",
    "        pathologies.append(int(p.strip()))\n",
    "    else:\n",
    "        raise Exception(f\"Primary pathology {p} not in dataset!\")\n",
    "splen_flags = list(map(int, args.splen.split(',')))\n",
    "min_ev_count = args.min_events\n",
    "\n",
    "selected_patient_ids, events = select_patients(Xstatic, event_counts, pathologies, splen_flags=splen_flags, min_ev_count=min_ev_count)\n",
    "print(f\"# [{args.pathologies}] PATIENTS: {len(selected_patient_ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dbe2Ck-_rc93"
   },
   "source": [
    "## Cross validation + embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "aborted",
     "timestamp": 1747823126555,
     "user": {
      "displayName": "Maurizio Giordano",
      "userId": "11661605724852130605"
     },
     "user_tz": -120
    },
    "id": "y1Glx1pXrcXX"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db94427504944a499eaab8e48a9edd11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Targets:   0%|          | 0/1188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1188, 1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66c945def74b46efa5663620fe3c21b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Folds:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0., 1.]), array([1014,  174])) count: 0\n",
      "\n",
      "🚀 Inizio cross-validation...\n",
      "\n",
      "X_static shape (950, 23) (238, 23) Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's MCC: 0.0527838\n",
      "X_static shape (950, 23) (238, 23) Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's MCC: 0.0516939\n",
      "X_static shape (950, 23) (238, 23) Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's MCC: 0\n",
      "X_static shape (951, 23) (237, 23) Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[101]\tvalid_0's MCC: 0.101251\n",
      "X_static shape (951, 23) (237, 23) Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's MCC: 0.139568\n",
      "\n",
      "📊 Risultati medi su 5 fold:\n",
      "📈 AUC:      0.5319 ± 0.0393\n",
      "🧪 F1-score: 0.1847 ± 0.1060\n",
      "⚖️ Precision:0.1629 ± 0.0823\n",
      "🔁 Recall:   0.2482 ± 0.1793\n",
      "🧮 MCC:      0.0691 ± 0.0476\n",
      "🎯 Accuracy: 0.7482 ± 0.0744\n",
      "\n",
      "🧩 Confusion Matrix finale (aggregata):\n",
      "[[846 168]\n",
      " [131  43]]\n",
      "0+1+2+3+4+5+6+7 & 1188 & $\\mathbf{X}^{\\text{static}}$ & $0.5319\\pm0.0393$ & $0.1847\\pm0.1060$ & $0.1629\\pm0.0823$ & $0.2482\\pm0.1793$ & $0.0691\\pm0.0476$ & [[846 168] [131  43]]\\\\ \n"
     ]
    }
   ],
   "source": [
    "# Embedding parameters\n",
    "num_epochs = 10  # 10\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 64  # 16\n",
    "hidden_dim = 128\n",
    "batch_size = 32\n",
    "\n",
    "window_size = 2  # for skipgram\n",
    "\n",
    "# LGBM parameters\n",
    "lgb_params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'None',\n",
    "    'verbosity': -3,\n",
    "    'is_unbalance': True\n",
    "}\n",
    "\n",
    "def mcc_eval(y_pred, dataset):\n",
    "    y_true = dataset.get_label()\n",
    "    y_pred_labels = (y_pred > 0.5).astype(int)\n",
    "    mcc = matthews_corrcoef(y_true, y_pred_labels)\n",
    "    return 'MCC', mcc, True\n",
    "\n",
    "mcc_scores = []\n",
    "acc_scores = []\n",
    "rocauc_scores = []\n",
    "prec_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "y_valid_all = []\n",
    "y_pred_all = []\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "zero_data = np.zeros((len(events.keys()),))\n",
    "y_df = pd.DataFrame(zero_data, columns=['target']).set_index(pd.Series([e for e in list(events.keys())]))\n",
    "cnt = 0\n",
    "for id, dcount in tqdm(events.items(), desc=\"Targets\"):\n",
    "    if len(set([e.lower() for e in dcount.keys()]).intersection(set(targets))) > 0:  # if there's at least one occurrence of the target set 1\n",
    "        y_df.loc[id, 'target'] = 1\n",
    "y = y_df.values.astype(np.float32).ravel()\n",
    "print(y_df.shape)\n",
    "cvfolding = tqdm(skf.split(selected_patient_ids, y), total=n_splits, desc=\"Folds\")\n",
    "print(np.unique(y_df.values, return_counts=True), f\"count: {cnt}\")\n",
    "\n",
    "use_vars = []\n",
    "for v in args.use_vars.split(\",\"):\n",
    "    if v.strip() in [\"static\", \"binary\", \"lstm\"]:\n",
    "        use_vars += [v.strip()]\n",
    "    else:\n",
    "        raise Exception(\"Wrong methid in paramters\")\n",
    "\n",
    "print(\"\\n🚀 Inizio cross-validation...\\n\")\n",
    "for fold, (t_idx, v_idx) in enumerate(cvfolding):\n",
    "\n",
    "    train_idx, valid_idx = selected_patient_ids[t_idx], selected_patient_ids[v_idx]\n",
    "    Xtrains = dict(zip(use_vars, [pd.DataFrame(index=train_idx)]* len(use_vars)))\n",
    "    Xtests = dict(zip(use_vars, [pd.DataFrame(index=valid_idx)]* len(use_vars)))\n",
    "    if \"lstm\" in use_vars:\n",
    "        train_sentences = [[word_to_idx[word] for word,_ in sequences[id]] for id in train_idx]\n",
    "        padded_train = pad_sequence([torch.tensor(s) for s in train_sentences], batch_first=True)\n",
    "        # Dataset e dataloader\n",
    "        embedding_dataset = TextDataset(padded_train)\n",
    "        dataloader = DataLoader(embedding_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "        # Inizializza e allena modello LSTM unidirezionale\n",
    "        embmodel = LSTMEmbeddingModel(len(word_to_idx), embed_dim=64, hidden_dim=128, pooling=False)\n",
    "        embmodel.train_model(dataloader, enable_plot=False, disable=False)\n",
    "        word_indices = [idx for word, idx in word_to_idx.items() if word != \"<PAD>\"]\n",
    "        word_tensors = torch.tensor(word_indices).unsqueeze(1)  # Shape (num_words, 1)\n",
    "        embedding = embmodel(word_tensors).detach().numpy()\n",
    "        W = pd.DataFrame(embedding.T, columns=[w.lower() for w in vocab])\n",
    "        X_df = similarity_matrix(events, embed_attributes, list(set(targets).intersection(vocab)), W, W)\n",
    "        Xtrains['lstm'] = X_df.loc[train_idx]\n",
    "        Xtests['lstm'] = X_df.loc[valid_idx]\n",
    "    if \"dome\" in use_vars:\n",
    "        raise Exception(\"DOME not included in demo...\")\n",
    "    if \"static\" in use_vars:\n",
    "        Xtrains['static'] = Xstatic.loc[train_idx]\n",
    "        Xtests['static'] = Xstatic.loc[valid_idx]\n",
    "    if \"binary\" in use_vars:\n",
    "        raise Exception(\"Binary not included in demo...\")\n",
    "    if \"dummy\" in use_vars:\n",
    "        Xtrains['dummy'] = pd.DataFrame(np.random.rand(len(train_idx), 128), index=train_idx)\n",
    "        Xtests['dummy'] = pd.DataFrame(np.random.rand(len(valid_idx), 128), index=valid_idx)\n",
    "    for v in use_vars:\n",
    "        print(f\"X_{v} shape {Xtrains[v].shape} {Xtests[v].shape}\", end=' ')\n",
    "    X_df_train = pd.concat(list(Xtrains.values()), axis=1)\n",
    "    X_df_tests = pd.concat(list(Xtests.values()), axis=1)\n",
    "    X_train, X_valid = X_df_train.values.astype(np.float32), X_df_tests.values.astype(np.float32)\n",
    "    y_train, y_valid = y_df.loc[train_idx].values.astype(np.float32).ravel(), y_df.loc[valid_idx].values.astype(np.float32).ravel()\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    valid_data = lgb.Dataset(X_valid, label=y_valid)\n",
    "\n",
    "    model = lgb.train(\n",
    "        lgb_params,\n",
    "        train_data,\n",
    "        num_boost_round=1000,\n",
    "        valid_sets=[valid_data],\n",
    "        feval=mcc_eval,\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(50),\n",
    "            lgb.log_evaluation(0)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    y_pred = model.predict(X_valid)\n",
    "    y_pred_labels = (y_pred > 0.5).astype(int)\n",
    "\n",
    "    # Metriche fold\n",
    "    mcc = matthews_corrcoef(y_valid, y_pred_labels)\n",
    "    acc = accuracy_score(y_valid, y_pred_labels)\n",
    "    rocauc = roc_auc_score(y_valid, y_pred)\n",
    "    prec = precision_score(y_valid, y_pred_labels)\n",
    "    recall = recall_score(y_valid, y_pred_labels)\n",
    "    f1 = f1_score(y_valid, y_pred_labels)\n",
    "\n",
    "    # Salva\n",
    "    mcc_scores.append(mcc)\n",
    "    acc_scores.append(acc)\n",
    "    rocauc_scores.append(rocauc)\n",
    "    prec_scores.append(prec)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    y_valid_all.extend(y_valid)\n",
    "    y_pred_all.extend(y_pred_labels)\n",
    "\n",
    "    # 🧠 Aggiorna tqdm\n",
    "    cvfolding.set_postfix({\n",
    "        \"Fold\": fold + 1,\n",
    "        \"MCC\": f\"{mcc:.4f}\",\n",
    "        \"AUC\": f\"{rocauc:.4f}\",\n",
    "        \"Acc\": f\"{acc:.4f}\",\n",
    "        \"F1\": f\"{f1:.4f}\"\n",
    "    })\n",
    "\n",
    "# Final confusion matrix\n",
    "cm_final = confusion_matrix(y_valid_all, y_pred_all)\n",
    "\n",
    "print(f\"\\n📊 Risultati medi su {n_splits} fold:\")\n",
    "print(f\"📈 AUC:      {np.mean(rocauc_scores):.4f} ± {np.std(rocauc_scores):.4f}\")\n",
    "print(f\"🧪 F1-score: {np.mean(f1_scores):.4f} ± {np.std(f1_scores):.4f}\")\n",
    "print(f\"⚖️ Precision:{np.mean(prec_scores):.4f} ± {np.std(prec_scores):.4f}\")\n",
    "print(f\"🔁 Recall:   {np.mean(recall_scores):.4f} ± {np.std(recall_scores):.4f}\")\n",
    "print(f\"🧮 MCC:      {np.mean(mcc_scores):.4f} ± {np.std(mcc_scores):.4f}\")\n",
    "print(f\"🎯 Accuracy: {np.mean(acc_scores):.4f} ± {np.std(acc_scores):.4f}\")\n",
    "\n",
    "print(f\"\\n🧩 Confusion Matrix finale (aggregata):\\n{cm_final}\")\n",
    "\n",
    "if args.display:\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(cm_final, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                xticklabels=['Pred 0', 'Pred 1'],\n",
    "                yticklabels=['True 0', 'True 1'])\n",
    "    plt.title('Final Confusion Matrix (all folds)')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if args.to_latex:\n",
    "    outstr = '||'.join(['\\\\mathbf{X}^{\\\\text{'+attrtype+'}}' for attrtype in use_vars])\n",
    "    print(f\"{'+'.join(args.pathologies.split(','))} & {len(selected_patient_ids)} \", end='')\n",
    "    print(f\"& ${outstr}$ & \", end='')\n",
    "    print(f\"${np.mean(rocauc_scores):.4f}\\\\pm{np.std(rocauc_scores):.4f}$ & \", end='')\n",
    "    print(f\"${np.mean(f1_scores):.4f}\\\\pm{np.std(f1_scores):.4f}$ & \", end='')\n",
    "    print(f\"${np.mean(prec_scores):.4f}\\\\pm{np.std(prec_scores):.4f}$ & \", end='')\n",
    "    print(f\"${np.mean(recall_scores):.4f}\\\\pm{np.std(recall_scores):.4f}$ & \", end='')\n",
    "    print(f\"${np.mean(mcc_scores):.4f}\\\\pm{np.std(mcc_scores):.4f}$ & \", end='')\n",
    "    print(f\"{cm_final}\".replace('\\n', ''), end='')\n",
    "    print(f\"\\\\\\\\ \\n\", end='')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMo6epXy2YjZkWW4R5gqA0B",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pygeometric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
